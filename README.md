# MapReduce Sorting with Hadoop Cluster üöÄ

[![Hadoop](https://img.shields.io/badge/Hadoop-3.3.6-orange.svg)](https://hadoop.apache.org/)
[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![Docker](https://img.shields.io/badge/Docker-Compose-2496ED.svg)](https://www.docker.com/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

## üìã Description

Impl√©mentation d'un algorithme de **tri distribu√©** utilisant le paradigme **MapReduce** sur un cluster Hadoop de 3 n≈ìuds. Ce projet d√©montre la puissance du traitement distribu√© pour trier 100 valeurs num√©riques en exploitant le framework Apache Hadoop.

### üéØ Objectifs

- ‚úÖ D√©ployer un cluster Hadoop multi-n≈ìuds avec Docker
- ‚úÖ Impl√©menter un tri MapReduce en Python
- ‚úÖ Comprendre les phases Map, Shuffle & Sort, Reduce
- ‚úÖ Monitorer les jobs via les interfaces Web Hadoop
- ‚úÖ Valider le tri distribu√©

## Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Hadoop Cluster (Docker)                 ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ
‚îÇ  ‚îÇ   Master     ‚îÇ    ‚îÇ   Worker 1   ‚îÇ              ‚îÇ
‚îÇ  ‚îÇ (NameNode)   ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ (DataNode)   ‚îÇ              ‚îÇ
‚îÇ  ‚îÇ (JobTracker) ‚îÇ    ‚îÇ (TaskTracker)‚îÇ              ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ
‚îÇ         ‚ñ≤                    ‚ñ≤                       ‚îÇ
‚îÇ         ‚îÇ                    ‚îÇ                       ‚îÇ
‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                       ‚îÇ
‚îÇ                  ‚îÇ                                   ‚îÇ
‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                            ‚îÇ
‚îÇ         ‚îÇ   Worker 2   ‚îÇ                            ‚îÇ
‚îÇ         ‚îÇ (DataNode)   ‚îÇ                            ‚îÇ
‚îÇ         ‚îÇ (TaskTracker)‚îÇ                            ‚îÇ
‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                            ‚îÇ
‚îÇ                                                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Flux MapReduce

```
Input (100 nombres non tri√©s)
        ‚Üì
   [Map Phase]
   - √âmet (nombre, nombre)
        ‚Üì
[Shuffle & Sort]
   - Hadoop trie automatiquement
        ‚Üì
  [Reduce Phase]
  - √âmet les nombres tri√©s
        ‚Üì
Output (100 nombres tri√©s)
```

## D√©marrage Rapide

### Pr√©requis

### Installation en 3 √©tapes

```bash
# 1. Cloner le d√©p√¥t
git clone https://github.com/8sylla/hadoop-mapreduce-sorting.git
cd hadoop-mapreduce-sorting

# 2. D√©marrer le cluster Hadoop
docker-compose up -d

# 3. Ex√©cuter le tri MapReduce
./scripts/run-sorting.sh
```

**C'est tout !** Les r√©sultats seront dans `data/output/`

## üìñ Guide D√©taill√©

### √âtape 1 : D√©marrer le cluster

```bash
# Construire l'image (si n√©cessaire)
docker-compose build

# D√©marrer les 3 conteneurs
docker-compose up -d

# V√©rifier que tout fonctionne
docker-compose ps
```

Vous devriez voir :
```
NAME              STATUS
hadoop-master     Up
hadoop-worker1    Up
hadoop-worker2    Up
```

### √âtape 2 : Initialiser Hadoop

```bash
# Entrer dans le conteneur master
docker exec -it hadoop-master bash

# Lancer Hadoop et YARN
./start-hadoop.sh

# V√©rifier HDFS
hdfs dfs -ls /
```

### √âtape 3 : G√©n√©rer les donn√©es

```bash
# Sur votre machine h√¥te
python src/python/generate_data.py

# Copier dans le conteneur
docker cp data/input/numbers.txt hadoop-master:/root/numbers.txt
```

### √âtape 4 : Ex√©cuter le Job MapReduce

```bash
# Dans le conteneur master
docker exec -it hadoop-master bash

# Cr√©er les r√©pertoires HDFS
hdfs dfs -mkdir -p /user/root/input
hdfs dfs -mkdir -p /user/root/output

# Charger les donn√©es
hdfs dfs -put numbers.txt /user/root/input/

# Lancer le job MapReduce
hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar \
  -input /user/root/input/numbers.txt \
  -output /user/root/output \
  -mapper "python3 mapper.py" \
  -reducer "python3 reducer.py" \
  -file mapper.py \
  -file reducer.py
```

### √âtape 5 : R√©cup√©rer les r√©sultats

```bash
# Afficher le r√©sultat dans HDFS
hdfs dfs -cat /user/root/output/part-00000

# Copier sur votre machine
hdfs dfs -get /user/root/output/part-00000 /root/sorted_result.txt
docker cp hadoop-master:/root/sorted_result.txt data/output/
```

## üñ•Ô∏è Interfaces Web

Une fois le cluster d√©marr√©, acc√©dez aux interfaces :

| Interface | URL | Description |
|-----------|-----|-------------|
| **HDFS NameNode** | http://localhost:9870 | Gestion du syst√®me de fichiers |
| **YARN ResourceManager** | http://localhost:8088 | Suivi des jobs MapReduce |
| **Worker 1** | http://localhost:8040 | Statut du worker 1 |
| **Worker 2** | http://localhost:8041 | Statut du worker 2 |

## üìä R√©sultats Attendus

### Input (data/input/numbers.txt)
```
847
123
956
42
...
```

### Output (data/output/part-00000)
```
1
7
12
42
...
998
```

### M√©triques

- **Temps d'ex√©cution** : ~30-60 secondes
- **Nombre de mappers** : 1-2 (selon split)
- **Nombre de reducers** : 1
- **Taille des donn√©es** : ~300 bytes

## üß™ Tests

### Test local (sans Hadoop)

```bash
# Pipeline complet en local
cat data/input/numbers.txt | \
  python src/python/mapper.py | \
  sort -n -k1 | \
  python src/python/reducer.py > data/output/local_result.txt

# Valider le tri
python src/python/validate_sort.py data/output/local_result.txt
```

### Tests unitaires

```bash
# Installer les d√©pendances
pip install -r requirements.txt

# Lancer les tests
python -m pytest tests/ -v
```

## üîß Configuration

### Modifier le nombre de valeurs

√âditez `src/python/generate_data.py` :

```python
# G√©n√©rer 1000 valeurs au lieu de 100
generate_random_numbers(count=1000, min_val=1, max_val=10000)
```

### Ajouter des reducers

Dans le job Hadoop :

```bash
-D mapreduce.job.reduces=3  # 3 reducers au lieu de 1
```

### Erreur "Connection refused" sur HDFS

```bash
# V√©rifier que Hadoop est d√©marr√©
docker exec hadoop-master jps

# Vous devez voir : NameNode, SecondaryNameNode, ResourceManager
```

### Job MapReduce √©choue

```bash
# V√©rifier les logs YARN
http://localhost:8088

# Nettoyer les anciens outputs
hdfs dfs -rm -r /user/root/output
```

## üôè Remerciements

- [Apache Hadoop](https://hadoop.apache.org/) pour le framework
- [liliasfaxi/hadoop-cluster](https://github.com/liliasfaxi/hadoop-cluster-docker) pour l'image Docker de base
- La communaut√© Big Data pour les ressources

---
